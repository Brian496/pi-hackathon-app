### Bug Bounty Template â€” Indirect Prompt Injection & Jailbreaks (Web3)

#### Title
Indirect Prompt Injection via [NFT/Token/Forum/Doc] Causes [Secret Exfiltration | Non-Allowlisted Egress | Risky Tx Staging]

#### Summary
Untrusted content processed by AI features can steer the model to exfiltrate secrets, invoke non-allowlisted network calls, or stage high-risk blockchain transactions without human approval.

#### Affected Surface
- Source: [tokenURI metadata | forum post | governance proposal | support ticket | synced Drive/Notion/GitHub doc]
- Ingestion path: [scraper/connector/browser]
- Tools/connectors impacted: [Drive | GitHub | Email | HTTP client | Wallet-ops bot]

#### Impact (map to OWASP LLM01/LLM02)
- Data exfiltration (API keys, RPC creds, webhook URLs)
- Tool abuse (connector-enabled lateral movement)
- Transaction staging/manipulation (dry-run templates, parameter pollution)

#### Reproduction Steps
1) Place payload at [URL/URI/Doc]
2) Ensure ingestion by AI feature [crawl/connector/agent]
3) Observe tool invocation / egress to [collector URL]; include logs (headers/URL)
4) Verify bypass of policy/guardrails (screenshots/logs)

#### Proof of Concept
- Payload content (exact text/HTML/markdown)
- Visibility (public/private) and location (tokenID, IPFS CID, doc link)
- Logs of model/tool actions; network traces; redacted secrets

#### Severity
Critical/High depending on demonstrated egress or transaction staging potential

#### Remediation
- Separate instructions from data; treat all external content as untrusted
- Implement allowlisted egress with deterministic validators; remove env secrets from model context
- Add canaries; require human approval for risky tools; reset session state per task

#### Safe Harbor
No real funds used; devnet/fork only; fake secrets; coordinated disclosure respected

